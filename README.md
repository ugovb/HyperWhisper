# HyperWhisper ğŸ™ï¸âœ¨

[![Swift](https://img.shields.io/badge/Swift-6.0-orange.svg)](https://swift.org)
[![Platform](https://img.shields.io/badge/Platform-macOS%2015%2B-blue.svg)](https://www.apple.com/macos/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

**AI-powered voice transcription for macOS** â€” Speak your thoughts, get clean text. Local-first, privacy-focused.

![HyperWhisper Demo](docs/demo.gif)

## âœ¨ Features

- ğŸ¯ **Push-to-Talk**: Hold `âŒ¥ Option` to record, release to transcribe
- ğŸ§  **AI Processing**: Clean up transcriptions with LLM post-processing
- ğŸ”’ **Privacy First**: All transcription happens locally with Parakeet
- âš¡ **Blazing Fast**: Neural Engine acceleration on Apple Silicon
- ğŸ“‹ **Auto-Paste**: Text automatically inserted into your active app
- ğŸ¨ **Custom Modes**: Create personas for different use cases (coding, emails, notes...)

## ğŸš€ Quick Start

### Option 1: Download DMG (Recommended)
1. Download the latest `HyperWhisper-Installer.dmg` from [Releases](../../releases)
2. Drag to Applications
3. Launch and follow the onboarding wizard

### Option 2: Build from Source
```bash
git clone https://github.com/YOUR_USERNAME/HyperWhisper.git
cd HyperWhisper
./build.sh
open HyperWhisper.app
```

## ğŸ“‹ Requirements

- macOS 15.0 (Sequoia) or later
- Apple Silicon (M1/M2/M3/M4) recommended
- ~500MB disk space for AI models
- Microphone access

## âš™ï¸ Configuration

### API Keys (Optional)
For cloud AI processing, you can configure API keys in Settings:

| Provider | Purpose | Get Key |
|----------|---------|---------|
| Gemini | File transcription | [Google AI Studio](https://aistudio.google.com/) |
| OpenRouter | Post-processing LLM | [OpenRouter](https://openrouter.ai/) |

> **Note**: Local transcription with Parakeet works without any API keys!

### Permissions
HyperWhisper needs:
- ğŸ¤ **Microphone**: For voice recording
- â™¿ **Accessibility**: For text insertion into apps

## ğŸ”§ Development

```bash
# Clone
git clone https://github.com/YOUR_USERNAME/HyperWhisper.git
cd HyperWhisper

# Run in debug mode
swift run

# Build release .app
./build.sh

# Create DMG for distribution
./create-dmg.sh
```

## ğŸ“ Project Structure

```
Sources/HyperWhisper/
â”œâ”€â”€ Core/           # Audio engine, AI engines
â”œâ”€â”€ Models/         # SwiftData models
â”œâ”€â”€ Services/       # LLM providers, system services
â”œâ”€â”€ UI/             # SwiftUI views
â””â”€â”€ HyperWhisperApp.swift
```

## ğŸ¤ Contributing

Contributions welcome! Please read [CONTRIBUTING.md](CONTRIBUTING.md) first.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [FluidAudio](https://github.com/FluidInference/FluidAudio) for Parakeet TDT integration
- [OpenRouter](https://openrouter.ai/) for unified LLM access
- Apple for Neural Engine and Swift

---

Made with â¤ï¸ for the macOS community
